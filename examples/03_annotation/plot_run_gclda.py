# emacs: -*- mode: python-mode; py-indent-offset: 4; tab-width: 4; indent-tabs-mode: nil -*-
# ex: set sts=4 ts=4 sw=4 et:
"""

.. _annotations1:

===============================
 Train a GCLDA model and use it
===============================

This example trains a generalized correspondence latent Dirichlet allocation
model using abstracts from Neurosynth and then uses it for decoding.

"""
import os

import numpy as np
import nibabel as nib
from nilearn.plotting import plot_stat_map

import nimare
from nimare import annotate, decode
from nimare.tests.utils import get_test_data_path

###############################################################################
# Load dataset with abstracts
# ---------------------------
# We'll load a small dataset composed only of studies in Neurosynth with
# Angela Laird as a coauthor, for the sake of speed.
dset = nimare.dataset.Dataset.load(
    os.path.join(get_test_data_path(), 'neurosynth_laird_studies.pkl.gz'))

###############################################################################
# Generate term counts
# --------------------
# GCLDA uses raw word counts instead of the tf-idf values generated by
# Neurosynth.
counts_df = annotate.text.generate_counts(
    dset.texts, text_column='abstract', tfidf=False, max_df=0.99, min_df=0)

###############################################################################
# Run model
# ---------
# Five iterations will take ~10 minutes with the full Neurosynth dataset.
# It's much faster with this reduced example dataset.
model = annotate.topic.GCLDAModel(
    counts_df, dset.coordinates, mask=dset.masker.mask_img)
model.fit(n_iters=10, loglikely_freq=5)
model.save('gclda_model.pkl.gz')

# Let's remove the model now that you know how to generate it.
os.remove('gclda_model.pkl.gz')

###############################################################################
# Decode an ROI image
# -------------------

# Make a small cubic ROI
arr = np.zeros(dset.masker.mask_img.shape, int)
arr[40:44, 45:49, 40:44] = 1
mask_img = nib.Nifti1Image(arr, dset.masker.mask_img.affine)

# Run the decoder
decoded_df, _ = decode.discrete.gclda_decode_roi(model, mask_img)
decoded_df.sort_values(by='Weight', ascending=False).head(10)

###############################################################################
# Generate a pseudo-statistic image from text
# -------------------------------------------
text = ('the amygdala and the hippocampus are very important for emotion and '
        'memory. the claustrum might do something too.')
encoded_img, _ = decode.encode.gclda_encode(model, text)
plot_stat_map(encoded_img, draw_cross=False)

###############################################################################
# Decode an unthresholded statistical map
# -------------------------------------------
# For the sake of simplicity, we will use the pseudo-statistic map generated
# in the previous step.

# Run the decoder
decoded_df, _ = decode.continuous.gclda_decode_map(model, encoded_img)
decoded_df.sort_values(by='Weight', ascending=False).head(10)
