{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save NIDM-Results packs to NiMARE dataset\n",
    "NOTE: This will ultimately be replaced with a simple `nidm2nimare` function in `nimare.io`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/.conda/envs/nimare_dev/lib/python3.7/site-packages/duecredit-0.6.4-py3.7.egg/duecredit/utils.py:32: DeprecationWarning: dist() and linux_distribution() functions are deprecated in Python 3.5\n",
      "  and platform.linux_distribution()[0] == 'debian' \\\n",
      "/home/james/.conda/envs/nimare_dev/lib/python3.7/site-packages/duecredit-0.6.4-py3.7.egg/duecredit/io.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import defaultdict, Iterator\n",
      "/home/james/.conda/envs/nimare_dev/lib/python3.7/site-packages/nipype-1.1.7-py3.7.egg/nipype/interfaces/base/traits_extension.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "/home/james/.conda/envs/nimare_dev/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/home/james/.conda/envs/nimare_dev/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/james/.conda/envs/nimare_dev/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from os.path import basename, join, isfile, dirname\n",
    "\n",
    "import nimare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _local_max(data, affine, min_distance):\n",
    "    \"\"\"Find all local maxima of the array, separated by at least min_distance.\n",
    "    Adapted from https://stackoverflow.com/a/22631583/2589328\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        3D array of with masked values for cluster.\n",
    "    min_distance : :obj:`int`\n",
    "        Minimum distance between local maxima in ``data``, in terms of mm.\n",
    "    Returns\n",
    "    -------\n",
    "    ijk : :obj:`numpy.ndarray`\n",
    "        (n_foci, 3) array of local maxima indices for cluster.\n",
    "    vals : :obj:`numpy.ndarray`\n",
    "        (n_foci,) array of values from data at ijk.\n",
    "    \"\"\"\n",
    "    # Initial identification of subpeaks with minimal minimum distance\n",
    "    data_max = ndimage.filters.maximum_filter(data, 3)\n",
    "    maxima = (data == data_max)\n",
    "    data_min = ndimage.filters.minimum_filter(data, 3)\n",
    "    diff = ((data_max - data_min) > 0)\n",
    "    maxima[diff == 0] = 0\n",
    "\n",
    "    labeled, n_subpeaks = ndimage.label(maxima)\n",
    "    ijk = np.array(ndimage.center_of_mass(data, labeled,\n",
    "                                          range(1, n_subpeaks + 1)))\n",
    "    ijk = np.round(ijk).astype(int)\n",
    "\n",
    "    vals = np.apply_along_axis(arr=ijk, axis=1, func1d=_get_val,\n",
    "                               input_arr=data)\n",
    "\n",
    "    # Sort subpeaks in cluster in descending order of stat value\n",
    "    order = (-vals).argsort()\n",
    "    vals = vals[order]\n",
    "    ijk = ijk[order, :]\n",
    "    xyz = nib.affines.apply_affine(affine, ijk)  # Convert to xyz in mm\n",
    "\n",
    "    # Reduce list of subpeaks based on distance\n",
    "    keep_idx = np.ones(xyz.shape[0]).astype(bool)\n",
    "    for i in range(xyz.shape[0]):\n",
    "        for j in range(i + 1, xyz.shape[0]):\n",
    "            if keep_idx[i] == 1:\n",
    "                dist = np.linalg.norm(xyz[i, :] - xyz[j, :])\n",
    "                keep_idx[j] = dist > min_distance\n",
    "    ijk = ijk[keep_idx, :]\n",
    "    vals = vals[keep_idx]\n",
    "    return ijk, vals\n",
    "\n",
    "\n",
    "def _get_val(row, input_arr):\n",
    "    \"\"\"Small function for extracting values from array based on index.\n",
    "    \"\"\"\n",
    "    i, j, k = row\n",
    "    return input_arr[i, j, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = join(dirname(nimare.__file__), 'tests', 'data', 'nidm_pain_dset.json')\n",
    "f2 = 'nidm_pain_dset_with_subpeaks.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict = {}\n",
    "folders = sorted(glob('/Users/tsalo/Downloads/nidm-pain-results/pain_*.nidm'))\n",
    "for folder in folders:\n",
    "    name = basename(folder)\n",
    "    ddict[name] = {}\n",
    "    ddict[name]['contrasts'] = {}\n",
    "    ddict[name]['contrasts']['1'] = {}\n",
    "    ddict[name]['contrasts']['1']['coords'] = {}\n",
    "    ddict[name]['contrasts']['1']['coords']['space'] = 'MNI'\n",
    "    ddict[name]['contrasts']['1']['images'] = {}\n",
    "    ddict[name]['contrasts']['1']['images']['space'] = 'MNI_2mm'\n",
    "    # con file\n",
    "    files = glob(join(folder, 'Contrast*.nii.gz'))\n",
    "    files = [f for f in files if 'StandardError' not in basename(f)]\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['con'] = f\n",
    "    # se file\n",
    "    files = glob(join(folder, 'ContrastStandardError*.nii.gz'))\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['se'] = f\n",
    "    # z file\n",
    "    files = glob(join(folder, 'ZStatistic*.nii.gz'))\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['z'] = f\n",
    "    # t file\n",
    "    # z file\n",
    "    files = glob(join(folder, 'TStatistic*.nii.gz'))\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['t'] = f\n",
    "    # sample size\n",
    "    f = join(folder, 'DesignMatrix.csv')\n",
    "    if isfile(f):\n",
    "        df = pd.read_csv(f, header=None)\n",
    "        n = [df.shape[0]]\n",
    "    else:\n",
    "        n = None\n",
    "    ddict[name]['contrasts']['1']['sample_sizes'] = n\n",
    "    # foci\n",
    "    files = glob(join(folder, 'ExcursionSet*.nii.gz'))\n",
    "    f = sorted(files)[0]\n",
    "    img = nib.load(f)\n",
    "    data = np.nan_to_num(img.get_data())\n",
    "    # positive clusters\n",
    "    binarized = np.copy(data)\n",
    "    binarized[binarized>0] = 1\n",
    "    binarized[binarized<0] = 0\n",
    "    binarized = binarized.astype(int)\n",
    "    labeled = ndimage.measurements.label(binarized, np.ones((3, 3, 3)))[0]\n",
    "    clust_ids = sorted(list(np.unique(labeled)[1:]))\n",
    "    ijk = np.hstack([np.where(data * (labeled == c) == np.max(data * (labeled == c))) for c in clust_ids])\n",
    "    ijk = ijk.T\n",
    "    xyz = nib.affines.apply_affine(img.affine, ijk)\n",
    "    ddict[name]['contrasts']['1']['coords']['x'] = list(xyz[:, 0])\n",
    "    ddict[name]['contrasts']['1']['coords']['y'] = list(xyz[:, 1])\n",
    "    ddict[name]['contrasts']['1']['coords']['z'] = list(xyz[:, 2])\n",
    "\n",
    "with open(f1, 'w') as fo:\n",
    "    json.dump(ddict, fo, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict = {}\n",
    "folders = sorted(glob('/Users/tsalo/Downloads/nidm-pain-results/pain_*.nidm'))\n",
    "for folder in folders:\n",
    "    name = basename(folder)\n",
    "    ddict[name] = {}\n",
    "    ddict[name]['contrasts'] = {}\n",
    "    ddict[name]['contrasts']['1'] = {}\n",
    "    ddict[name]['contrasts']['1']['coords'] = {}\n",
    "    ddict[name]['contrasts']['1']['coords']['space'] = 'MNI'\n",
    "    ddict[name]['contrasts']['1']['images'] = {}\n",
    "    ddict[name]['contrasts']['1']['images']['space'] = 'MNI_2mm'\n",
    "    # con file\n",
    "    files = glob(join(folder, 'Contrast*.nii.gz'))\n",
    "    files = [f for f in files if 'StandardError' not in basename(f)]\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['con'] = f\n",
    "    # se file\n",
    "    files = glob(join(folder, 'ContrastStandardError*.nii.gz'))\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['se'] = f\n",
    "    # z file\n",
    "    files = glob(join(folder, 'ZStatistic*.nii.gz'))\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['z'] = f\n",
    "    # t file\n",
    "    # z file\n",
    "    files = glob(join(folder, 'TStatistic*.nii.gz'))\n",
    "    if files:\n",
    "        f = sorted(files)[0]\n",
    "    else:\n",
    "        f = None\n",
    "    ddict[name]['contrasts']['1']['images']['t'] = f\n",
    "    # sample size\n",
    "    f = join(folder, 'DesignMatrix.csv')\n",
    "    if isfile(f):\n",
    "        df = pd.read_csv(f, header=None)\n",
    "        n = [df.shape[0]]\n",
    "    else:\n",
    "        n = None\n",
    "    ddict[name]['contrasts']['1']['sample_sizes'] = n\n",
    "    # foci\n",
    "    files = glob(join(folder, 'ExcursionSet*.nii.gz'))\n",
    "    f = sorted(files)[0]\n",
    "    img = nib.load(f)\n",
    "    data = np.nan_to_num(img.get_data())\n",
    "    # positive clusters\n",
    "    binarized = np.copy(data)\n",
    "    binarized[binarized>0] = 1\n",
    "    binarized[binarized<0] = 0\n",
    "    binarized = binarized.astype(int)\n",
    "    labeled = ndimage.measurements.label(binarized, np.ones((3, 3, 3)))[0]\n",
    "    clust_ids = sorted(list(np.unique(labeled)[1:]))\n",
    "    \n",
    "    peak_vals = np.array([np.max(data * (labeled == c)) for c in clust_ids])\n",
    "    clust_ids = [clust_ids[c] for c in (-peak_vals).argsort()]  # Sort by descending max value\n",
    "\n",
    "    ijk = []\n",
    "    for c_id, c_val in enumerate(clust_ids):\n",
    "        cluster_mask = labeled == c_val\n",
    "        masked_data = data * cluster_mask\n",
    "\n",
    "        # Get peaks, subpeaks and associated statistics\n",
    "        subpeak_ijk, subpeak_vals = _local_max(masked_data, img.affine,\n",
    "                                               min_distance=8)\n",
    "\n",
    "        # Only report peak and, at most, top 3 subpeaks.\n",
    "        n_subpeaks = np.min((len(subpeak_vals), 4))\n",
    "        #n_subpeaks = len(subpeak_vals)\n",
    "        subpeak_ijk = subpeak_ijk[:n_subpeaks, :]\n",
    "        ijk.append(subpeak_ijk)\n",
    "    ijk = np.vstack(ijk)\n",
    "    xyz = nib.affines.apply_affine(img.affine, ijk)\n",
    "    ddict[name]['contrasts']['1']['coords']['x'] = list(xyz[:, 0])\n",
    "    ddict[name]['contrasts']['1']['coords']['y'] = list(xyz[:, 1])\n",
    "    ddict[name]['contrasts']['1']['coords']['z'] = list(xyz[:, 2])\n",
    "\n",
    "\n",
    "with open(f2, 'w') as fo:\n",
    "    json.dump(ddict, fo, sort_keys=True, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
